{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition Script\n",
    "This script tries to recognize handwritten images previous training against the MNIST dataset. The main feature of this script is that aims to create sequential neural networks using the Keras library.\n",
    "\n",
    "## Imports\n",
    "First section of the script consists in importing the required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/ianmcloughlin/jupyter-teaching-notebooks/blob/master/mnist.ipynb\n",
    "import keras as kr\n",
    "from keras.models import load_model\n",
    "import sklearn.preprocessing as pre\n",
    "import gzip\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables\n",
    "After imports, the global variables are defined or declared\n",
    "* enconder: it converts multi-class labels to binary labels (belong or does not belong to the class). Since our classes are well known, decimal digits, the enconder can be defined early.\n",
    "* model: it represent the neural network model to load/create/train/test or validate\n",
    "This variables are read and modified from various functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "\t\ttest_lbl = f.read()\n",
    "test_lbl = np.array(list(test_lbl[ 8:])).astype(np.uint8)\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(test_lbl)\n",
    "\n",
    "# Global model variable\n",
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "Next are the definition of the different functions of this script\n",
    "\n",
    "### Load Function\n",
    "It prompts the user for an HDF5 file that contains a Keras neural network model. That model is going to be stored in the global variable *model*. As a last step it displays a summary of the model, so the user can have an idea about the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "\tglobal model\n",
    "\tfilename = input(\"Please enter a HDF5 file to load: \")\n",
    "\tmodel = load_model(filename)\n",
    "\tmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Function\n",
    "This function creates and configures a model. It overwrites the *model* global variable so any previous model stored in this variable is destroyed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct():\n",
    "\tglobal model\n",
    "\tif model:\n",
    "\t\tconfirmation = input(\"\\nDo you want to delete the saved model? (y/n) \")\n",
    "\t\tif confirmation == \"y\":\n",
    "\t\t\tdel model\n",
    "\t\telif confirmation == \"n\":\n",
    "\t\t\treturn\n",
    "\t\n",
    "\tmodel = kr.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predefined neural network type is sequential, meaning one layer of neurons after another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tmodel = kr.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of neuron layers created by this script is four:\n",
    "* input layer: 784 neurons\n",
    "* second layer: 600 neurons, activation function: linear\n",
    "* third layer: 400 neurons, activation function: relu\n",
    "* output layer: 10 neurons, activation function: softmax\n",
    "\n",
    "The [activation functions](https://keras.io/activations/) can be changed to the ones specified in the Keras documentation.\n",
    "\n",
    "The compile options are:\n",
    "* loss function: categorical_crossentropy\n",
    "* optimizer: adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(kr.layers.Dense(units=600, activation='linear', input_dim=784))\n",
    "model.add(kr.layers.Dense(units=400, activation='relu'))\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally a model of the just configured model is displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tmodel.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Function\n",
    "As its name suggests, this function trains a neural network stored in the global variable *model*. First checks that the global variable *model* is not empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\tglobal model\n",
    "\tglobal encoder\n",
    "\t\n",
    "\tif not model:\n",
    "\t\tprint(\"No model found. Please create or load your model first\")\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, it uncompress the training files containing the images of the MNIST handwritten numbers and their respective labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\twith gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "\t\ttrain_img = f.read()\n",
    "\n",
    "\twith gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "\t\ttrain_lbl = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local variables *train_img* and *train_lbl* are defined. The variable *train_img* skips the first 16 header bytes of the images file and the proceeds to store the images as 60000 matrices of size 28 by 28 unsigned bytes. Each image is processed by the NOT bitwise operand, since the background and foreground of the MNIST are black and white, the scripts invert them to obtain a more common black foreground over white background image. Each matrix is divided by the scalar *255.0* to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "\ttrain_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The digits labels have a similar treatment. They are stored in the local variable *train_lbl*, skipping the first 8 hearder bytes of the labels file. Labels are stored in an unidimensional array of 1 row and 60000 columns of type unsinged bytes, each containing a label for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\ttrain_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the images are \"flateen\" into a two-dimensional array of 60000 rows, each row is an image, and 784 unsigned byte columns, each column represents a pixel of the MNIST 28x28 image. This is done in order to match a single pixel with a single input neuron of the model. Also, for performance purposes avoided nested *for* loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tinputs = train_img.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\toutputs = encoder.transform(train_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summary of the model to be trained is displayed to the user, for verification and rememberance purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model training starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d9757d8577d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\tmodel.fit(inputs, outputs, epochs=2, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Function\n",
    "This function is in charge of testing a model against MNIST image test set. As good practice, it checks if the model is not empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "\tglobal model\n",
    "\tglobal encoder\n",
    "\tglobal test_lbl\n",
    "\t\n",
    "\tif not model:\n",
    "\t\tprint(\"Empty model. Please create/load a model first\")\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it uncompress the image test file, and processes the images the same exact way the train function does: it skips the first 16 header bytes of the images file and the proceeds to store the images as 10000 matrices of size 28 by 28 unsigned bytes. Each image is processed by the NOT bitwise operand, since the background and foreground of the MNIST are black and white, the scripts invert them to obtain a more common black foreground over white background image. Each matrix is divided by the scalar 255.0 to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\twith gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "\t\ttest_img = f.read()\n",
    "\t\t\n",
    "\ttest_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model summary is display to remind about the model that is going to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model starts predicting over the array of normalized flatten test images, since the predictions are arrays of float numbers between 0 and 1, they are *inversed transformed* to the category label, that is to the respective predicted digit (0 - 9):  \n",
    "```\n",
    "prediction: [[9.7214666e-05 8.9237624e-01 8.1143016e-03 2.9746909e-03 7.8786700e-04 6.9424585e-02 3.3270712e-03 3.2408212e-04 2.0257998e-02 2.3161303e-03]]\n",
    "```\n",
    "The closest value to 1 it is the second element in the array that corresponds to the label category for digit *1*. That is the work that `encoder.inverse_transform` does. Each prediction is compared to its respective label, if the prediction is successful the `rs` success counter is increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tresult_set = (encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the success rate is calculated and displayed to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tpercent = (result_set/10000)*100\n",
    "\tprint(\"\\nModel has made\", result_set, \"successful predictions out of 10000 tests (\", percent, \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Function\n",
    "This functions checks for a model stored in the global variable *model*, if so, it proceeds to save it in an HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "\tglobal model\n",
    "\t# Save model\n",
    "\tif not model:\n",
    "\t\tprint(\"There is no model!\\nPlease create/load a model first\")\n",
    "\t\treturn\n",
    "\n",
    "\tfilename = input(\"Please enter a filename: \")\n",
    "\tmodel.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read PNG Image function\n",
    "As before the fuction returns to the main menu in case of an empty model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def png_read():\n",
    "\tif not model:\n",
    "\t\tprint(\"There is no model!\\nPlease create/load a model first\")\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then asks the user for the PNG image filename. Then it converts it to grayscale coloring with the `convert(\"L\")` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *img_width* and *img_height* are used to scale the image. They are intialized 28 pixels each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\timg_width = 28\n",
    "\timg_height = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user is asked to input new dimensions that are compatible with the model input size or press 'Enter' to leave as it is and not scale.\n",
    "            \n",
    "The `img.thumbnail((img_width,img_height), Image.ANTIALIAS)` function call performs the scaling if the image's original dimensions were changed.\n",
    "\n",
    "The processing dimensions are displayed to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tif (img_width != img.size[0]) or (img_height != img.size[1]):\n",
    "\t\timg.thumbnail((img_width,img_height), Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the process to 'flatten' the image is perform multiplying the processing dimensions. For example, let's say the PNG image dimensions are 375 by 375 pixels and we have a model with 784 input neurons. The product 375x375 = 140625 is clearly not equal to the model's input 784. To solve this, since the image dimensional ratio is 1:1, we can scale the image down to 28 by 28 pixels, since 28x28 = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tone_dim =  img_width*img_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `im2arr` variable is defined with the pixel bytes of the scaled (or not) image. Then it is 'flatten' following a similar procedure in the previuous *train* and *test* functions: it is reshaped into a one-dimensional array of 784 columns each representing each pixel usigned byte of the image. They are divided by the scalar *255.0* to normalize the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tim2arr = np.array(img.getdata())\n",
    "\tim2arr = np.array(list(im2arr)).reshape(1, one_dim).astype(np.uint8) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the model makes a prediction, wich is reversed encoded to display more clearly the predicted class, or digit in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tpred = model.predict(im2arr)\n",
    "\tresult_set = encoder.inverse_transform(pred)\n",
    "\tprint(\"The program predicts the image is a:\", result_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menu\n",
    "The menu displays the operation that the user can perform with this script. There are 7 items that the user can choose from. The option is stored in the *choice* variable and then parsed for function execution. The functions are the ones described in the previous sections. If an invalid option number (e.g. *0*) or other invalid character (e.g. *A*), the script yields an `Invalid choice, enter a valid number.` error and asks for correct input. Option *7* exits the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = True\n",
    "while choice:\n",
    "\tprint(\"\"\"\n",
    "\t1. Load HDF5 file\n",
    "\t2. Create a NN model\n",
    "\t3. Train with MNIST training images\n",
    "\t4. Test using MNIST testing images\n",
    "\t5. Save model\n",
    "\t6. Read and predict from a PNG file\n",
    "\t7. Exit\n",
    "\t\"\"\")\n",
    "\tchoice = input(\"Menu: \")\n",
    "\t\n",
    "\tif choice == \"1\":\n",
    "\t\tload()\n",
    "\telif choice ==\"2\":\n",
    "\t\tconstruct()\n",
    "\telif choice ==\"3\":\n",
    "\t\ttrain()\n",
    "\telif choice==\"4\":\n",
    "\t\ttest()\n",
    "\telif choice ==\"5\":\n",
    "\t\tsave()\n",
    "\telif choice ==\"6\":\n",
    "\t\tpng_read()\n",
    "\telif choice==\"7\":\n",
    "\t\tchoice = None\n",
    "\telse:\n",
    "\t\tprint(\"Invalid choice, enter a valid number.\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
